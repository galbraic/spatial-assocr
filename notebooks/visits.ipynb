{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "sys.setrecursionlimit(10000)\n",
    "%matplotlib inline\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "pd.options.mode.chained_assignment = None # turn off SettingWithCopyWarning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Parcel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>epoch_time</th>\n",
       "      <th>day_id</th>\n",
       "      <th>seconds_since_monday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.559170e+05</td>\n",
       "      <td>6.559170e+05</td>\n",
       "      <td>655917.000000</td>\n",
       "      <td>655917.000000</td>\n",
       "      <td>655917.000000</td>\n",
       "      <td>6.559170e+05</td>\n",
       "      <td>655917.000000</td>\n",
       "      <td>655917.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.319007e+06</td>\n",
       "      <td>7.921562e+08</td>\n",
       "      <td>241633.977727</td>\n",
       "      <td>-117.878281</td>\n",
       "      <td>33.740011</td>\n",
       "      <td>1.441100e+09</td>\n",
       "      <td>114.426144</td>\n",
       "      <td>324717.879480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.652273e+06</td>\n",
       "      <td>1.001908e+09</td>\n",
       "      <td>191189.068282</td>\n",
       "      <td>0.097180</td>\n",
       "      <td>0.104993</td>\n",
       "      <td>5.944586e+06</td>\n",
       "      <td>68.802527</td>\n",
       "      <td>174493.396071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>2.940000e+02</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-118.115560</td>\n",
       "      <td>33.388260</td>\n",
       "      <td>1.431313e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.156263e+06</td>\n",
       "      <td>5.413332e+07</td>\n",
       "      <td>61905.000000</td>\n",
       "      <td>-117.922940</td>\n",
       "      <td>33.665890</td>\n",
       "      <td>1.436230e+09</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>162146.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.301512e+06</td>\n",
       "      <td>2.876739e+08</td>\n",
       "      <td>211459.000000</td>\n",
       "      <td>-117.911910</td>\n",
       "      <td>33.778800</td>\n",
       "      <td>1.440782e+09</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>330765.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.483557e+06</td>\n",
       "      <td>1.219463e+09</td>\n",
       "      <td>409421.000000</td>\n",
       "      <td>-117.837490</td>\n",
       "      <td>33.811010</td>\n",
       "      <td>1.446231e+09</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>481287.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.272555e+07</td>\n",
       "      <td>4.724669e+09</td>\n",
       "      <td>661044.000000</td>\n",
       "      <td>-117.446930</td>\n",
       "      <td>33.945950</td>\n",
       "      <td>1.452279e+09</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>604798.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           event_id       user_id    location_id            lon  \\\n",
       "count  6.559170e+05  6.559170e+05  655917.000000  655917.000000   \n",
       "mean   6.319007e+06  7.921562e+08  241633.977727    -117.878281   \n",
       "std    3.652273e+06  1.001908e+09  191189.068282       0.097180   \n",
       "min    8.000000e+01  2.940000e+02       9.000000    -118.115560   \n",
       "25%    3.156263e+06  5.413332e+07   61905.000000    -117.922940   \n",
       "50%    6.301512e+06  2.876739e+08  211459.000000    -117.911910   \n",
       "75%    9.483557e+06  1.219463e+09  409421.000000    -117.837490   \n",
       "max    1.272555e+07  4.724669e+09  661044.000000    -117.446930   \n",
       "\n",
       "                 lat    epoch_time         day_id  seconds_since_monday  \n",
       "count  655917.000000  6.559170e+05  655917.000000         655917.000000  \n",
       "mean       33.740011  1.441100e+09     114.426144         324717.879480  \n",
       "std         0.104993  5.944586e+06      68.802527         174493.396071  \n",
       "min        33.388260  1.431313e+09       1.000000              2.000000  \n",
       "25%        33.665890  1.436230e+09      58.000000         162146.000000  \n",
       "50%        33.778800  1.440782e+09     111.000000         330765.000000  \n",
       "75%        33.811010  1.446231e+09     174.000000         481287.000000  \n",
       "max        33.945950  1.452279e+09     244.000000         604798.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [\"event_id\", \"user_id\", \"location_id\", \"lon\", \"lat\", \"epoch_time\", \"day_id\", \"seconds_since_monday\"]\n",
    "\n",
    "# USER SPECIFIC IMPORT\n",
    "# directory = \"C:\\\\Users\\\\alexj\\\\Documents\\\\Research\\\\twitter\\\\parcel_ass\\\\oc\\\\\"  # alex\n",
    "# directory = os.path.join(\"~\", \"dev\", \"CSAFE\", \"spatial-assocr\", \"data\", \"parcel_ass\", \"oc\")  # chris\n",
    "# events = pd.read_csv(directory + \"ass_events.csv\", header = None, names = names)\n",
    "# data = pd.read_csv(os.path.join(directory, \"ass_events_no_filter.csv\"), header = None, names = names)\n",
    "\n",
    "# GENERIC IMPORT (using files in the repo)\n",
    "directory = os.path.join(\"..\", \"data\")  # generic\n",
    "data = pd.read_csv(os.path.join(directory, \"parcel_ass-oc-ass_events_no_filter.csv\"), header = None, names = names)\n",
    "data.sort_values(['user_id', 'epoch_time'], inplace=True)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visits  \n",
    "\n",
    "Moshe created visits by _replac[ing] tweets\n",
    "occurring with the same hour and within 50 meters of each\n",
    "other with a single effective tweet._ \n",
    "\n",
    "Note that the `epoch_time` column contains timestamps (not sure the timezone) with a milisecond resolution. We will use that column to create visits in a similar fashion that also incorporates the location of the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0.05  # 50 m\n",
    "t = 60**2  # number of s in one hr\n",
    "\n",
    "def spherical_dist(pos1, r=6371):\n",
    "    \"\"\"\n",
    "    return distance matrix in km\n",
    "    \n",
    "    https://stackoverflow.com/questions/19413259/efficient-way-to-calculate-distance-matrix-given-latitude-and-longitude-data-in\n",
    "    \"\"\"\n",
    "    pos2 = np.array(pos1)\n",
    "    pos1 = np.array(pos1)[:, None]\n",
    "    pos1 = np.deg2rad(pos1)\n",
    "    pos2 = np.deg2rad(pos2)\n",
    "    cos_lat1 = np.cos(pos1[..., 0])\n",
    "    cos_lat2 = np.cos(pos2[..., 0])\n",
    "    cos_lat_d = np.cos(pos1[..., 0] - pos2[..., 0])\n",
    "    cos_lon_d = np.cos(pos1[..., 1] - pos2[..., 1])\n",
    "    return r * np.arccos(cos_lat_d - cos_lat1 * cos_lat2 * (1 - cos_lon_d))\n",
    "\n",
    "def temporal_dist(times):\n",
    "    \"\"\"matrix of time differences\"\"\"\n",
    "    times = np.array(times)\n",
    "    return np.abs(np.subtract.outer(times, times))\n",
    "\n",
    "def invert_dict(d): \n",
    "    \"\"\"reverse a dictionary with list/set values\"\"\"\n",
    "    inverse = dict() \n",
    "    for key in d: \n",
    "        for item in d[key]:\n",
    "            inverse[item] = key\n",
    "    return inverse\n",
    "\n",
    "def set_visits(df):\n",
    "    \"\"\"\n",
    "    :param df: pd.DataFrame for one user with <lat, lon, epoch_time> columns\n",
    "    :return: same pd.DataFrame with a visit column containing integer visit id\n",
    "    \"\"\"\n",
    "    # find groups of points that meet both the dist and time criteria for a visit\n",
    "    distance_match = spherical_dist(df[['lat', 'lon']]) <= d\n",
    "    time_match = temporal_dist(df['epoch_time']) <= t\n",
    "    matches = distance_match & time_match\n",
    "    # groups = [[] for __ in range(len(matches))]\n",
    "    # for row_i, row in enumerate(matches):\n",
    "    #     v = set([i for i, is_true in enumerate(row) if is_true])\n",
    "    #     groups[row_i] = v\n",
    "    groups = {}\n",
    "    i = 0\n",
    "    for row_i, row in enumerate(matches):\n",
    "        v = list([i for i, is_true in enumerate(row) if is_true])\n",
    "        if v not in groups.values():\n",
    "            groups[i] = v\n",
    "            i += 1\n",
    "    df['visit'] = invert_dict(groups).values()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply to the entire data set & save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = data.groupby('user_id').apply(set_visits)\n",
    "pop_deduped = data.drop_duplicates(['user_id', 'location_id', 'visit'])\n",
    "\n",
    "pop.to_csv(os.path.join(directory, \"parcel_ass-oc-visits-ass_events_no_filter.csv\"), index=False)\n",
    "pop_deduped.to_csv(os.path.join(directory, \"parcel_ass-oc-visits-ass_events_deduped.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(655917, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(545697, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_deduped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format & filter for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_filter_data(df, time_span='month', n_k=30):\n",
    "    \"\"\"\n",
    "    Filter to users with at least n_k events in 2 sequential time_spans\n",
    "    \n",
    "    df: pd.DataFrame containing {user_id, day_id } columns \n",
    "    time_span: str in {'week', 'month', 'bimonth'}\n",
    "    n_k: number of events a user must have in each time_span\n",
    "    \"\"\"\n",
    "    t_vals = {\n",
    "        'week': 7,\n",
    "        'month': 30,\n",
    "        'bimonth': 60,\n",
    "    }\n",
    "    t = t_vals.get(time_span)\n",
    "    if t is None:\n",
    "        return print(\"Enter a valid time_span... {'week', 'month', 'bimonth'}\")\n",
    "\n",
    "    # reset day id to start at 0\n",
    "    df[\"day_id\"] = df[\"day_id\"] - df[\"day_id\"].min()\n",
    "    \n",
    "    # calculate time_used ids\n",
    "    df[time_span] = data.day_id // t\n",
    "    \n",
    "    # calc nevents in each time_span for each user & filter by min threshold\n",
    "    counts = df.groupby([\"user_id\", time_span]).count()[\"event_id\"]\n",
    "    view = counts[counts >= n_k].reset_index()\n",
    "    \n",
    "    # join together to have a row for each user for a single time_span joined \n",
    "    # with the prior and next time_span\n",
    "    lagged_view = pd.concat(\n",
    "        [view, view.shift(1), view.shift(2)], \n",
    "        axis = 1\n",
    "    )\n",
    "    lagged_view.columns = list(\"next_\" + view.columns) + \\\n",
    "        list(view.columns) + list(\"last_\" + view.columns)\n",
    "    \n",
    "    # filter rows so that they only contain pairs where there is a sequential time_span present\n",
    "    right_users = (lagged_view[\"user_id\"] == lagged_view[\"next_user_id\"]) | \\\n",
    "        (lagged_view[\"user_id\"] == lagged_view[\"last_user_id\"])\n",
    "    sequential = ((lagged_view[\"next_\"+time_span] - lagged_view[time_span]) == 1) | \\\n",
    "        ((lagged_view[time_span] - lagged_view[\"last_\"+time_span]) == 1)\n",
    "    filtered = lagged_view[right_users & sequential][[\"user_id\", time_span, \"event_id\"]].reset_index(drop=True)\n",
    "    \n",
    "    # gather ids and valid weeks for the users that have survived the filtering\n",
    "    user_time_dict = {-1 : []}\n",
    "    for i, x in filtered.iterrows():\n",
    "        user_id = x[\"user_id\"]\n",
    "        time = x[time_span]\n",
    "        if user_id not in user_time_dict:\n",
    "            user_time_dict[user_id] = []\n",
    "        user_time_dict[user_id].append(time)\n",
    "        \n",
    "    # reduce the original data to be only valid events\n",
    "    out = pd.merge(left=filtered, right=df, on=[\"user_id\", time_span], how=\"left\")    \n",
    "    \n",
    "    return out, user_time_dict\n",
    "\n",
    "\n",
    "def create_mpp(df: pd.DataFrame, user_dict: dict):\n",
    "    \"\"\"create a dataframe contianing the data to be analyzed\"\"\"\n",
    "    # get the user_ids that met the criteria in the first 2 months\n",
    "    keep = []\n",
    "    for uid, months in user_dict.items():\n",
    "        if all(x in months for x in [0., 1.]):\n",
    "            keep.append(uid)\n",
    "\n",
    "    # create the mpp data frame\n",
    "    mpp = df.loc[(df['user_id'].isin(keep)) & (df['month'].isin({0., 1.})),].reset_index()\n",
    "    mpp['m'] = np.where(mpp['month'] == 0., 'a', 'b')\n",
    "    \n",
    "    # remap user id for easier handling\n",
    "    user_dict = {}\n",
    "    index = 1\n",
    "    for ident in mpp.user_id.unique():\n",
    "        if ident not in user_dict:\n",
    "            user_dict[ident] = index\n",
    "            index += 1\n",
    "\n",
    "    mpp[\"new_user_id\"] = mpp.user_id.apply(lambda x: user_dict[x])\n",
    "    \n",
    "    return mpp[['user_id', 'new_user_id', 'm', 'lon', 'lat', 'location_id']].rename(index=str, columns={\"user_id\": \"old_uid\", \"new_user_id\": \"uid\"}), keep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILTERED VISITS\n",
      "Users:  544\n",
      "Visits: 123781\n"
     ]
    }
   ],
   "source": [
    "time_span = 'month'\n",
    "n_visits = 20\n",
    "\n",
    "filtered_visits, filtered_users = sequential_filter_data(\n",
    "    pop_deduped, time_span=time_span, n_k=n_visits\n",
    ")\n",
    "print(\"FILTERED VISITS\")\n",
    "print(\"Users: \", filtered_visits['user_id'].nunique())\n",
    "print(\"Visits:\", len(filtered_visits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPP DATA (at least 20 visits in each of the first two months)\n",
      "Users:  223\n",
      "Visits: 28052\n"
     ]
    }
   ],
   "source": [
    "mpp, keep = create_mpp(filtered_visits, filtered_users)\n",
    "mpp.to_csv(os.path.join(directory, \"mpp_visits_month0a_month1b_n20.csv\"), index=False)\n",
    "print(\"MPP DATA (at least {} visits in each of the first two {}s)\".format(n_visits, time_span))\n",
    "print(\"Users: \", mpp['uid'].nunique())\n",
    "print(\"Visits:\", len(mpp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events\n",
      "----------------\n",
      "Month 1:  14654 (65.7 per user)\n",
      "Month 2:  13398 (60.1 per user)\n"
     ]
    }
   ],
   "source": [
    "n_users = mpp['uid'].nunique()\n",
    "print(\"Number of events\")\n",
    "print(\"----------------\")\n",
    "print(\"Month 1: \", sum(mpp.m == 'a'), \"({} per user)\".format(round(sum(mpp.m == 'a')/n_users, 1)))\n",
    "print(\"Month 2: \", sum(mpp.m == 'b'), \"({} per user)\".format(round(sum(mpp.m == 'b')/n_users, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_uid</th>\n",
       "      <th>uid</th>\n",
       "      <th>m</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2554741.0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>-117.83335</td>\n",
       "      <td>33.74851</td>\n",
       "      <td>546927.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2554741.0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>-117.67779</td>\n",
       "      <td>33.47102</td>\n",
       "      <td>517182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2554741.0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>-117.83513</td>\n",
       "      <td>33.76453</td>\n",
       "      <td>543461.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2554741.0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>-117.70361</td>\n",
       "      <td>33.46636</td>\n",
       "      <td>130291.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2554741.0</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>-117.64253</td>\n",
       "      <td>33.44296</td>\n",
       "      <td>500205.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     old_uid  uid  m        lon       lat  location_id\n",
       "0  2554741.0    1  a -117.83335  33.74851     546927.0\n",
       "1  2554741.0    1  a -117.67779  33.47102     517182.0\n",
       "2  2554741.0    1  a -117.83513  33.76453     543461.0\n",
       "3  2554741.0    1  a -117.70361  33.46636     130291.0\n",
       "4  2554741.0    1  a -117.64253  33.44296     500205.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_uid</th>\n",
       "      <th>uid</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.805200e+04</td>\n",
       "      <td>28052.000000</td>\n",
       "      <td>28052.000000</td>\n",
       "      <td>28052.000000</td>\n",
       "      <td>28052.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.179048e+09</td>\n",
       "      <td>128.918473</td>\n",
       "      <td>-117.866609</td>\n",
       "      <td>33.729012</td>\n",
       "      <td>295309.355483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.112455e+09</td>\n",
       "      <td>65.778755</td>\n",
       "      <td>0.104304</td>\n",
       "      <td>0.103459</td>\n",
       "      <td>182011.081528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.554741e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-118.110960</td>\n",
       "      <td>33.405590</td>\n",
       "      <td>906.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.375534e+08</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>-117.928950</td>\n",
       "      <td>33.646970</td>\n",
       "      <td>111024.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.489599e+08</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>-117.890210</td>\n",
       "      <td>33.726360</td>\n",
       "      <td>296304.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.377573e+09</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>-117.794690</td>\n",
       "      <td>33.812050</td>\n",
       "      <td>435556.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.167795e+09</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>-117.560810</td>\n",
       "      <td>33.944970</td>\n",
       "      <td>661032.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            old_uid           uid           lon           lat    location_id\n",
       "count  2.805200e+04  28052.000000  28052.000000  28052.000000   28052.000000\n",
       "mean   1.179048e+09    128.918473   -117.866609     33.729012  295309.355483\n",
       "std    1.112455e+09     65.778755      0.104304      0.103459  182011.081528\n",
       "min    2.554741e+06      1.000000   -118.110960     33.405590     906.000000\n",
       "25%    1.375534e+08     72.000000   -117.928950     33.646970  111024.000000\n",
       "50%    7.489599e+08    136.000000   -117.890210     33.726360  296304.000000\n",
       "75%    2.377573e+09    191.000000   -117.794690     33.812050  435556.000000\n",
       "max    3.167795e+09    223.000000   -117.560810     33.944970  661032.000000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMP Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER 1\n",
      "Number of unique locations: 31\n",
      "Number of matched users: 11\n",
      "Number of sample points: 1253\n",
      "Sum of weights: 1.0\n"
     ]
    }
   ],
   "source": [
    "def get_sample_space(df, user_id):\n",
    "    # user's location set is all unique parcels visited regardless of month\n",
    "    loc_set = df.loc[mpp['uid'] == user_id]['location_id'].unique()\n",
    "    \n",
    "    # sample space is any other users' data in either month\n",
    "    samp_sp = df.loc[(df.uid != user_id)]\n",
    "\n",
    "    # loop over users in sample space counting number of overlapped parcels\n",
    "    matches = []\n",
    "    for u in samp_sp.uid.unique():\n",
    "        tmp = samp_sp.loc[samp_sp.uid == u]\n",
    "        shared_locs = np.intersect1d(\n",
    "            loc_set,\n",
    "            tmp['location_id'].unique()\n",
    "        )\n",
    "        if len(shared_locs) > 0:\n",
    "            matches.append(\n",
    "                {\n",
    "                    'uid': u,\n",
    "                    'n_matches': len(shared_locs),\n",
    "                    'n_events': len(tmp)\n",
    "                }\n",
    "            )\n",
    "    matches = pd.DataFrame(matches)\n",
    "\n",
    "    # compute the weight for each matching user's points\n",
    "    tot_matches = sum(matches['n_matches'])\n",
    "    matches['w'] = matches['n_matches'] / (tot_matches  * matches['n_events'])\n",
    "    matches.drop(['n_events', 'n_matches'], axis=1, inplace=True)\n",
    "\n",
    "    # limit the sample space\n",
    "    samp_sp = pd.merge(samp_sp, matches, on='uid')\n",
    "    print('USER', user_id)\n",
    "    print('Number of unique locations:', len(loc_set))\n",
    "    print('Number of matched users:', samp_sp.uid.nunique())\n",
    "    print('Number of sample points:', len(samp_sp))\n",
    "    print('Sum of weights:', round(sum(samp_sp.w), 2))\n",
    "    \n",
    "    return samp_sp\n",
    "\n",
    "samp_sp = get_sample_space(mpp, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial-assocr",
   "language": "python",
   "name": "spatial-assocr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
